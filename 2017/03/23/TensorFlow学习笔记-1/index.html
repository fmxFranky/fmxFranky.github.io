<!DOCTYPE html>
<html >
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="Mx Feng" />



<meta name="description" content="本文为自己看别人写的tf代码时的总结,希望以后会用到.第一部分主要是关于conv layer和变量定义还有BN trick的相关总结,主要以代码为主

一些要提前注意的点


一个好的习惯是将一些常用的tf中已经有的函数重新封装一遍,这种封装主要体现在变量定义和操作定义上面.其好处在于将函数的参数变少
对于一些常用的conv和deconv操作,一定要弄清楚NHWC的参数值,避免出错
定义变量一定要">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow学习笔记-1">
<meta property="og:url" content="http://yoursite.com/2017/03/23/TensorFlow学习笔记-1/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="本文为自己看别人写的tf代码时的总结,希望以后会用到.第一部分主要是关于conv layer和变量定义还有BN trick的相关总结,主要以代码为主

一些要提前注意的点


一个好的习惯是将一些常用的tf中已经有的函数重新封装一遍,这种封装主要体现在变量定义和操作定义上面.其好处在于将函数的参数变少
对于一些常用的conv和deconv操作,一定要弄清楚NHWC的参数值,避免出错
定义变量一定要">
<meta property="og:image" content="https://ooo.0o0.ooo/2017/03/23/58d3817630994.png">
<meta property="og:updated_time" content="2017-03-23T09:18:15.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow学习笔记-1">
<meta name="twitter:description" content="本文为自己看别人写的tf代码时的总结,希望以后会用到.第一部分主要是关于conv layer和变量定义还有BN trick的相关总结,主要以代码为主

一些要提前注意的点


一个好的习惯是将一些常用的tf中已经有的函数重新封装一遍,这种封装主要体现在变量定义和操作定义上面.其好处在于将函数的参数变少
对于一些常用的conv和deconv操作,一定要弄清楚NHWC的参数值,避免出错
定义变量一定要">
<meta name="twitter:image" content="https://ooo.0o0.ooo/2017/03/23/58d3817630994.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>TensorFlow学习笔记-1 | Hexo</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: undefined
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Mx Feng</a></h1>
        </hgroup>

        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:fmxFranky@gmail.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/fmxFranky" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/MacOS/">MacOS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Software/">Software</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/图像处理/">图像处理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">星垂平野阔,月涌大江流</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Mx Feng</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Mx Feng</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:fmxFranky@gmail.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/fmxFranky" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-TensorFlow学习笔记-1" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/03/23/TensorFlow学习笔记-1/" class="article-date">
      <time datetime="2017-03-23T08:52:41.000Z" itemprop="datePublished">2017-03-23</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      TensorFlow学习笔记-1
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/学习笔记/">学习笔记</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>本文为自己看别人写的tf代码时的总结,希望以后会用到.第一部分主要是关于conv layer和变量定义还有BN trick的相关总结,主要以代码为主</p>
<blockquote>
<p>一些要提前注意的点</p>
</blockquote>
<ul>
<li>一个好的习惯是将一些常用的tf中已经有的函数重新封装一遍,这种封装主要体现在变量定义和操作定义上面.其好处在于将函数的参数变少</li>
<li>对于一些常用的conv和deconv操作,一定要弄清楚NHWC的参数值,避免出错</li>
<li>定义变量一定要有<code>name</code></li>
<li>tf的数据格式是NHWC</li>
</ul>
<blockquote>
<p>变量定义</p>
</blockquote>
<p>直接利用tf定义</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">weights = tf.truncated_normal(name, shape, stddev)</div><div class="line">biases = tf.constant(<span class="number">0.0</span>, shape)</div></pre></td></tr></table></figure>
<p>封装版1.0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape, stddev=<span class="number">0.02</span>, name=None)</span>:</span></div><div class="line">    initial = tf.truncated_normal(shape, stddev=stddev)</div><div class="line">    <span class="keyword">return</span> tf.Variable(initial) <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">else</span> tf.get_variable(name, initializer=initial)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape, name=None)</span>:</span></div><div class="line">    initial = tf.constant(<span class="number">0.0</span>, shape)</div><div class="line">    <span class="keyword">return</span> tf.Variable(initial) <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">else</span> tf.get_variable(name, initializer=initial)</div><div class="line">weights = weight_variable(name, shape)</div><div class="line">biases = bias_variable(name, shape)</div></pre></td></tr></table></figure>
<p>这里要注意的就是在有无name的情况下选择的初始化函数.</p>
<p>封装版2.0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_variable_on_cpu</span><span class="params">(name, shape, initializer)</span>:</span></div><div class="line">    <span class="string">"""Helper to create a Variable stored on CPU memory.</span></div><div class="line">    Args:</div><div class="line">    name: name of the variable</div><div class="line">    shape: list of ints</div><div class="line">    initializer: initializer for Variable</div><div class="line">    Returns:</div><div class="line">    Variable Tensor</div><div class="line">    """</div><div class="line">    <span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</div><div class="line">    var = tf.get_variable(name, shape, initializer=initializer)</div><div class="line">    <span class="keyword">return</span> var</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_variable_with_weight_decay</span><span class="params">(name, shape, stddev, wd)</span>:</span></div><div class="line">    <span class="string">"""Helper to create an initialized Variable with weight decay.</span></div><div class="line">    Note that the Variable is initialized with a truncated normal distribution.</div><div class="line">    A weight decay is added only if one is specified.</div><div class="line">    Args:</div><div class="line">    name: name of the variable</div><div class="line">    shape: list of ints</div><div class="line">    stddev: standard deviation of a truncated Gaussian</div><div class="line">    wd: add L2Loss weight decay multiplied by this float. If None, weight</div><div class="line">        decay is not added for this Variable.</div><div class="line">    Returns:</div><div class="line">    Variable Tensor</div><div class="line">    """</div><div class="line">    var = _variable_on_cpu(name, shape,</div><div class="line">                         tf.truncated_normal_initializer(stddev=stddev))</div><div class="line">    <span class="keyword">if</span> wd:</div><div class="line">    weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name=<span class="string">'weight_loss'</span>)</div><div class="line">    tf.add_to_collection(<span class="string">'losses'</span>, weight_decay)</div><div class="line">    <span class="keyword">return</span> var</div><div class="line">weights = _variable_with_weight_decay(<span class="string">'weights'</span>, shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">64</span>, <span class="number">64</span>],stddev=<span class="number">1e-4</span>, wd=<span class="number">0.0</span>)</div><div class="line">biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">64</span>],tf.constant_initializer(<span class="number">0.1</span>))</div></pre></td></tr></table></figure>
<blockquote>
<p>构建一个conv layer</p>
</blockquote>
<p>tf中的conv2d</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=<span class="keyword">True</span>, data_format=<span class="keyword">None</span>, name=<span class="keyword">None</span>)</div></pre></td></tr></table></figure>
<p>按照官网的API,有以下几点需要注意:</p>
<ul>
<li>这里的<code>input</code>和<code>filter</code>的tensor_shape要求一致,</li>
<li><code>input</code>的shape为:<code>[batch, in_height, in_width, in_channels]</code></li>
<li><code>filters</code>的shape为:<code>[filter_height, filter_width, in_channels, out_channels]</code></li>
<li>默认数据格式<code>data_format</code>是<code>&quot;NHWC&quot;</code></li>
<li><code>padding</code>一般取<code>&quot;SAME&quot;</code>,即保持卷积之后的尺寸不变</li>
<li><code>strides</code>的shape为:<code>[batch_skip, stride_h_skip, stride_w_skip, in_channels_skip]</code>,<strong>由于batch里面的每一个训练数据和输入的每个通道都会被用于训练</strong>,因此官方要求<code>strides</code>的使用格式应该是<code>[1, stride_skip, stride_skip, 1]</code>.第二个和第三个代表窗口(卷积核)的滑动步长,一般是一样的.</li>
</ul>
<p>掌握这个函数的用法之后就会发现,定义一层普通的conv layer只需要分三步:</p>
<ol>
<li>定义好<code>weights</code>,biases<code>,</code>strides`</li>
<li>应用函数<code>tf.nn.conv2d(input, weights, strides, name)</code>,<code>tf.nn.bias_add(conv, biases)</code></li>
<li>选择进行其他操作,如使用激活函数/池化/正则化</li>
</ol>
<p><strong>注意,由于整个网络的输入不一定是规则的(比如GAN,输入的是一个1-D的noise),所以这个时候一般采用<code>tf.matmul(input, W) + b</code>和<code>tf.reshape</code>方式构建第一个conv layer,进而将输入转化成为标准的tensor</strong></p>
<p>进一步地,利用上面的变量定义封装2.0,可以构建一个conv-&gt;pool-&gt;norm:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'conv'</span>) <span class="keyword">as</span> scope:</div><div class="line">    weights = _variable_with_weight_decay(<span class="string">'weights'</span>, shape=[<span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">64</span>], stddev=<span class="number">1e-4</span>, wd=<span class="number">0.0</span>)</div><div class="line">    conv = tf.nn.conv2d(images, kernel, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line">    biases = _variable_on_cpu(<span class="string">'biases'</span>, [<span class="number">64</span>], tf.constant_initializer(<span class="number">0.0</span>))</div><div class="line">    bias = tf.nn.bias_add(conv, biases)</div><div class="line">    conv = tf.nn.relu(bias, name=scope.name)</div><div class="line">    _activation_summary(conv1)</div><div class="line">pool = tf.nn.max_pool(conv1, ksize=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=<span class="string">'pool'</span>)</div><div class="line">norm = tf.nn.lrn(pool1, <span class="number">4</span>, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>, name=<span class="string">'norm'</span>)</div></pre></td></tr></table></figure>
<blockquote>
<p>变量初始化的Tricks</p>
</blockquote>
<p>对于神经网络的训练过程而言,梯度消失是一个很重的问题,而实践证明,weights的初始化对于梯度的影响很大.所以从几个不同的方面有几种不同的解决办法可以借鉴一下</p>
<p>基于方差方面的考量,我们认为<strong>为了使得网络中信息更好的流动,每一层输出的方差应该尽量相等</strong>,于是xavier_init方法应运而生,这种方法在2010年被提出,近几年才得到关注,见paper <a href="http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf" target="_blank" rel="external">Understanding the Difficult of Training Deep Feedforward Neural Networks</a></p>
<p>其思路很简单,把<code>weights</code>的方差固定为<code>2/(n_in+n_out)</code>,其中<code>n_in</code>和<code>n_out</code>是<code>filters</code>的<code>shape[2]</code>和<code>shape[3]</code>,具体见下面的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable_xavier_initialized</span><span class="params">(shape, constant=<span class="number">1</span>, name=None)</span>:</span></div><div class="line">    stddev = constant * np.sqrt(<span class="number">2.0</span> / (shape[<span class="number">2</span>] + shape[<span class="number">3</span>]))</div><div class="line">    <span class="keyword">return</span> weight_variable(shape, stddev, name=name)</div></pre></td></tr></table></figure>
<p>直接使用<em>Batch Normalization Layer</em>.我们想要的是在非线性activation之前,输出值应该有比较好的分布(例如高斯分布)以便于back propagation时计算gradient,更新<code>weights</code>,Batch Normalization将输出值强行做一次Gaussian Normalization和线性变换:<br>        <img src="https://ooo.0o0.ooo/2017/03/23/58d3817630994.png" alt=""><br>Batch Normalization中所有的操作都是平滑可导,这使得back propagation可以有效运行并学到相应的参数γ,β.需要注意的一点是Batch Normalization在training和testing时行为有所差别.Training时μβ和σβ由当前batch计算得出;在Testing时μβ和σβ应使用Training时保存的均值或类似的经过处理的值,而不是由当前batch计算.</p>
<p>使用BN的方法可以自己实现,也可以直接使用tf的contrib模块里面的现成函数.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="comment"># 自己实现的BN</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_norm</span><span class="params">(x, nb_filters_out, phase_train, scope=<span class="string">'bn'</span>, decay=<span class="number">0.9</span>, eps=<span class="number">1e-5</span>, stddev=<span class="number">0.02</span>)</span>:</span></div><div class="line">    <span class="keyword">with</span> tf.variable(scope):</div><div class="line">        beta = tf.get_variable(name=<span class="string">'beta'</span>, shape=[nb_filters_out], initializer=tf.constant_initializer(<span class="number">0.0</span>), trainable=<span class="keyword">True</span>)</div><div class="line">        gamma = tf.get_variable(name=<span class="string">'gamma'</span>, shape=[nb_filters_out], initializer=tf.random_normal_initializer(<span class="number">1.0</span>, stddev), trainable=<span class="keyword">True</span>)</div><div class="line">        <span class="comment"># 用moments函数计算mean和var,其中[1,2,3]是只计算前三个axes</span></div><div class="line">        batch_mean, batch_var = tf.nn.moments(x, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], name=<span class="string">'moments'</span>)</div><div class="line">        ema = tf.trian.ExponentialMovingAverage(decay=decay)</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">mean_var_with_update</span><span class="params">()</span>:</span></div><div class="line">            ema_apply_op = ema.apply([batch_mean, batch_var])</div><div class="line">            <span class="keyword">with</span> tf.control_dependencies([ema_apply_op]):</div><div class="line">                <span class="keyword">return</span> tf.identity(batch_mean), tf.identity(batch_var)</div><div class="line"></div><div class="line">        mean, var = tf.cond(phase_train, mean_var_with_update, <span class="keyword">lambda</span>: (ema.average(batch_mean), ema.average(batch_var)))</div><div class="line">        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)</div><div class="line"></div><div class="line"><span class="comment"># tf官方contrib模块的函数</span></div><div class="line">tf.contrib.layers.batch_norm(x, decay=<span class="number">0.9</span>, center=<span class="keyword">True</span>, scale=<span class="keyword">True</span>, epsilon=<span class="number">1e-5</span>, is_training=<span class="keyword">True</span>, scope=<span class="string">'bn'</span>)</div></pre></td></tr></table></figure>

      
    </div>
    
  </div>
  
    


    <nav id="article-nav">
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2017/03/05/科研向Atom配置教程/">
                    科研向Atom配置教程
                </a>
            </div>
        
    </nav>

  
</article>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"TensorFlow学习笔记-1　| Hexo　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/" title="回到主页"><i class="fa fa-home"></i></a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2017/03/05/科研向Atom配置教程/" title="下一篇: 科研向Atom配置教程">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/03/23/TensorFlow学习笔记-1/">TensorFlow学习笔记-1</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/05/科研向Atom配置教程/">科研向Atom配置教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/04/DehazeNet-An-End-to-End-System-for-Single-Image-Haze-Removal/">DehazeNet,An End-to-End System for Single Image Haze Removal</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/04/Single-Image-Dehazing-via-Multi-scale-Convolutional-Neural-Networks/">Single Image Dehazing via Multi-scale Convolutional Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/03/MacOS配置及APP推荐/">MacOS配置及APP推荐</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/02/Image-De-raining-Using-a-Conditional-Generative-Adversarial-Network/">Image De-raining Using a Conditional Generative Adversarial Network</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2017 Mx Feng
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 2;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
             articleNav: "#article-nav a, #post-nav-button a", 
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>